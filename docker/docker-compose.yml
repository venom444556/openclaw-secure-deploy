# ============================================================
# PGPClaw — Docker Compose (Unified Stack)
#
# Profiles:
#   core       — OpenBao + OpenClaw gateway
#   monitoring — Prometheus, Grafana, Alertmanager, n8n
#   oauth      — Nango + PostgreSQL + Redis
#   full       — All of the above
#   build      — Build ephemeral runner + gateway images (not running services)
#
# Usage:
#   docker compose --profile core up -d
#   docker compose --profile full up -d
#   docker compose --profile build build
# ============================================================

networks:
  pgpclaw-internal:
    driver: bridge
    # NOTE: On Docker Desktop (macOS), 'internal: true' blocks port publishing
    # to the host. Port security is enforced via 127.0.0.1 bind in port mappings.
    # Ephemeral runners use --network none for full isolation.

services:

  # ════════════════════════════════════════════════════════════
  # CORE PROFILE
  # ════════════════════════════════════════════════════════════

  # ── OpenBao (Secrets Broker) ────────────────────────────────
  openbao:
    image: openbao/openbao:2.5.0
    container_name: pgpclaw-openbao
    restart: unless-stopped
    profiles: ["core", "full"]
    command: server -config=/openbao/config/config.hcl
    ports:
      - "127.0.0.1:8200:8200"               # Loopback only — host access for scripts + gateway
    volumes:
      - openbao_data:/openbao/file
      - openbao_audit:/openbao/audit
      - ../openbao/config.hcl:/openbao/config/config.hcl:ro
    cap_drop:
      - ALL
    cap_add:
      - IPC_LOCK                              # Required for mlock (even with disable_mlock)
      - SETGID                                # Required for su-exec user switch in entrypoint
      - SETUID                                # Required for su-exec user switch in entrypoint
    security_opt:
      - no-new-privileges:true
    networks:
      - pgpclaw-internal
    environment:
      BAO_ADDR: "http://127.0.0.1:8200"
    healthcheck:
      test: ["CMD-SHELL", "bao status -format=json 2>/dev/null | grep -q '\"sealed\": false' || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 15s
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"

  # ── OpenClaw Gateway ────────────────────────────────────────
  openclaw:
    image: pgpclaw/openclaw-gateway:local
    container_name: pgpclaw-gateway
    restart: unless-stopped
    profiles: ["core", "full"]
    user: "1001:1001"
    command: ["openclaw", "gateway", "run", "--dev", "--auth", "token", "--token", "${OPENCLAW_AUTH_PASSWORD:-changeme}"]
    # SECURITY NOTE: On Docker Desktop (macOS), network_mode: host doesn't work
    # (Docker runs in a VM). We use explicit port mapping with loopback binding.
    # Accesses OpenBao via host.docker.internal:8200 from inside the container.
    # Mitigated by: cap_drop ALL, no-new-privileges, non-root user, 127.0.0.1 bind.
    ports:
      - "127.0.0.1:18789:18789"               # Gateway WebSocket + HTTP
    volumes:
      - ~/.openclaw:/home/openclaw/.openclaw
      - ../config/openclaw.json:/home/openclaw/.openclaw/openclaw.json:ro
      - ./seccomp.json:/etc/openclaw/seccomp.json:ro
      - ~/.openclaw/skills/council:/home/openclaw/.openclaw/skills/council:ro
      - ~/.openclaw/skills/council-pro:/home/openclaw/.openclaw/skills/council-pro:ro
    environment:
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-}
      - ANTHROPIC_BASE_URL=http://msd-api-tracker:8080
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - OPENROUTER_API_KEY=${OPENROUTER_API_KEY:-}
      - DEEPSEEK_API_KEY=${DEEPSEEK_API_KEY:-}
      - XAI_API_KEY=${XAI_API_KEY:-}
      - GOOGLE_API_KEY=${GOOGLE_API_KEY:-}
      - TELEGRAM_BOT_TOKEN=${TELEGRAM_BOT_TOKEN:-}
      - DISCORD_BOT_TOKEN=${DISCORD_BOT_TOKEN:-}
      - OPENCLAW_AUTH_PASSWORD=${OPENCLAW_AUTH_PASSWORD:-}
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    networks:
      - pgpclaw-internal
    depends_on:
      openbao:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:18789/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "5"

  # ════════════════════════════════════════════════════════════
  # MONITORING PROFILE
  # ════════════════════════════════════════════════════════════

  # ── Prometheus (Metrics) ────────────────────────────────────
  prometheus:
    image: prom/prometheus:v3.9.1
    container_name: pgpclaw-prometheus
    restart: unless-stopped
    profiles: ["monitoring", "full"]
    ports:
      - "127.0.0.1:9090:9090"
    volumes:
      - ../monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ../monitoring/alerts.yml:/etc/prometheus/alerts.yml:ro
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=30d'
      - '--storage.tsdb.retention.size=5GB'
      - '--web.enable-otlp-receiver'
    security_opt:
      - no-new-privileges:true
    networks:
      - pgpclaw-internal

  # ── Grafana (Dashboard) ─────────────────────────────────────
  grafana:
    image: grafana/grafana:12.3.3
    container_name: pgpclaw-grafana
    restart: unless-stopped
    profiles: ["monitoring", "full"]
    ports:
      - "127.0.0.1:3000:3000"
    volumes:
      - grafana_data:/var/lib/grafana
      - ../monitoring/grafana-dashboards:/etc/grafana/provisioning/dashboards:ro
      - ../monitoring/grafana-datasources.yml:/etc/grafana/provisioning/datasources/datasources.yml:ro
      - ../monitoring/grafana-alerting:/etc/grafana/provisioning/alerting:ro
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD:-admin}
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_SERVER_ROOT_URL=http://localhost:3000
      - GF_SECURITY_CONTENT_SECURITY_POLICY=true
      - GF_SECURITY_X_CONTENT_TYPE_OPTIONS=true
      - GF_SECURITY_X_XSS_PROTECTION=true
      - GF_SECURITY_STRICT_TRANSPORT_SECURITY=true
      - GF_INSTALL_PLUGINS=grafana-oncall-app
      - GF_PLUGINS_ALLOW_LOADING_UNSIGNED_PLUGINS=grafana-oncall-app
      - GF_FEATURE_TOGGLES_ENABLE=externalServiceAccounts
    security_opt:
      - no-new-privileges:true
    networks:
      - pgpclaw-internal
    depends_on:
      - prometheus

  # ── Alertmanager (Alert Routing) ────────────────────────────
  alertmanager:
    image: prom/alertmanager:v0.31.1
    container_name: pgpclaw-alertmanager
    restart: unless-stopped
    profiles: ["monitoring", "full"]
    ports:
      - "127.0.0.1:9093:9093"
    volumes:
      - ../monitoring/alertmanager.yml:/etc/alertmanager/alertmanager.yml:ro
    security_opt:
      - no-new-privileges:true
    networks:
      - pgpclaw-internal
    depends_on:
      - prometheus

  # ── Blackbox Exporter (HTTP Probing) ───────────────────────
  blackbox:
    image: prom/blackbox-exporter:v0.25.0
    container_name: pgpclaw-blackbox
    restart: unless-stopped
    profiles: ["monitoring", "full"]
    volumes:
      - ../monitoring/blackbox.yml:/etc/blackbox_exporter/config.yml:ro
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    networks:
      - pgpclaw-internal
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "2"

  # ── Loki (Log Aggregation) ──────────────────────────────────
  loki:
    image: grafana/loki:3.5.0
    container_name: pgpclaw-loki
    restart: unless-stopped
    profiles: ["monitoring", "full"]
    ports:
      - "127.0.0.1:3100:3100"
    volumes:
      - ../monitoring/loki-config.yml:/etc/loki/config.yml:ro
      - loki_data:/loki
    command: -config.file=/etc/loki/config.yml
    security_opt:
      - no-new-privileges:true
    networks:
      - pgpclaw-internal
    healthcheck:
      test: ["CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:3100/ready || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"

  # ── Vector (Log Shipper — replaces Promtail) ──────────────────
  vector:
    image: timberio/vector:0.45.0-alpine
    container_name: pgpclaw-vector
    restart: unless-stopped
    profiles: ["monitoring", "full"]
    volumes:
      - ../monitoring/vector.yml:/etc/vector/vector.yml:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - /var/log/commission-audit:/var/log/commission-audit:ro
    command: --config /etc/vector/vector.yml
    security_opt:
      - no-new-privileges:true
    networks:
      - pgpclaw-internal
    depends_on:
      loki:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "wget --no-verbose --tries=1 --spider http://127.0.0.1:8686/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 15s
    logging:
      driver: "json-file"
      options:
        max-size: "20m"
        max-file: "2"

  # ── n8n (Workflow Automation) ───────────────────────────────
  n8n:
    image: n8nio/n8n:2.9.1
    container_name: pgpclaw-n8n
    restart: unless-stopped
    profiles: ["monitoring", "full"]
    ports:
      - "127.0.0.1:5678:5678"
    volumes:
      - n8n_data:/home/node/.n8n
    environment:
      - N8N_SECURE_COOKIE=true
      - N8N_DIAGNOSTICS_ENABLED=false
      - N8N_METRICS=true
      - N8N_METRICS_INCLUDE_DEFAULT_METRICS=true
      - N8N_METRICS_INCLUDE_WORKFLOW_ID_LABEL=true
      - WEBHOOK_URL=http://localhost:5678/
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-}
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - TELEGRAM_BOT_TOKEN=${TELEGRAM_BOT_TOKEN:-}
    security_opt:
      - no-new-privileges:true
    networks:
      - pgpclaw-internal
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"

  # ── PDF Renderer (Headless Chrome for HTML→PDF) ────────────
  pdf-renderer:
    image: ghcr.io/browserless/chromium:latest
    container_name: pgpclaw-pdf-renderer
    restart: unless-stopped
    profiles: ["monitoring", "full"]
    environment:
      - TOKEN=sas-pdf-token
      - CONCURRENT=2
      - TIMEOUT=30000
    security_opt:
      - no-new-privileges:true
    networks:
      - pgpclaw-internal
    logging:
      driver: "json-file"
      options:
        max-size: "20m"
        max-file: "2"

  # ── OnCall Redis (Celery broker — separate from nango-redis) ─
  oncall-redis:
    image: redis:7-alpine
    container_name: pgpclaw-oncall-redis
    restart: unless-stopped
    profiles: ["monitoring", "full"]
    user: "999:999"
    command: redis-server --maxmemory 64mb --maxmemory-policy allkeys-lru --save ""
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    networks:
      - pgpclaw-internal
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "2"

  # ── Grafana OnCall Engine ───────────────────────────────────
  oncall:
    image: grafana/oncall:latest
    container_name: pgpclaw-oncall
    restart: unless-stopped
    profiles: ["monitoring", "full"]
    ports:
      - "127.0.0.1:8090:8080"   # 8080 taken by msd-api-tracker
    volumes:
      - oncall_data:/var/lib/oncall
    environment:
      - BASE_URL=http://localhost:3000
      - SECRET_KEY=${ONCALL_SECRET_KEY:-change-me-must-be-32chars-minimum}
      - REDIS_URI=redis://pgpclaw-oncall-redis:6379/0
      - DATABASE_TYPE=sqlite3
      - DJANGO_SETTINGS_MODULE=settings.hobby
      - BROKER_TYPE=redis
      - GRAFANA_API_URL=http://pgpclaw-grafana:3000
    security_opt:
      - no-new-privileges:true
    networks:
      - pgpclaw-internal
    depends_on:
      oncall-redis:
        condition: service_healthy
      grafana:
        condition: service_started
    healthcheck:
      test: ["CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:8080/health/ || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"

  # ════════════════════════════════════════════════════════════
  # OAUTH PROFILE
  # ════════════════════════════════════════════════════════════

  # ── Nango PostgreSQL ────────────────────────────────────────
  nango-db:
    image: postgres:16.12-alpine
    container_name: pgpclaw-nango-db
    restart: unless-stopped
    profiles: ["oauth", "full"]
    environment:
      POSTGRES_DB: nango
      POSTGRES_USER: nango
      POSTGRES_PASSWORD: ${NANGO_DB_PASSWORD:-changeme}
    volumes:
      - nango_db_data:/var/lib/postgresql/data
    security_opt:
      - no-new-privileges:true
    networks:
      - pgpclaw-internal
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U nango"]
      interval: 10s
      timeout: 5s
      retries: 5
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"

  # ── Nango Redis ─────────────────────────────────────────────
  nango-redis:
    image: redis:7.4.7
    container_name: pgpclaw-nango-redis
    restart: unless-stopped
    profiles: ["oauth", "full"]
    command: redis-server --maxmemory 128mb --maxmemory-policy allkeys-lru
    volumes:
      - nango_redis_data:/data
    security_opt:
      - no-new-privileges:true
    networks:
      - pgpclaw-internal
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"

  # ── Nango Server (OAuth Proxy) ──────────────────────────────
  nango-server:
    image: nangohq/nango-server:hosted-0.69.30
    container_name: pgpclaw-nango-server
    restart: unless-stopped
    profiles: ["oauth", "full"]
    ports:
      - "127.0.0.1:3003:3003"               # API
      - "127.0.0.1:3009:3009"               # Connect UI
    environment:
      NANGO_DB_HOST: nango-db
      NANGO_DB_PORT: "5432"
      NANGO_DB_NAME: nango
      NANGO_DB_USER: nango
      NANGO_DB_PASSWORD: ${NANGO_DB_PASSWORD:-changeme}
      NANGO_ENCRYPTION_KEY: ${NANGO_ENCRYPTION_KEY:-}
      NANGO_SERVER_URL: "http://localhost:3003"
      SERVER_PORT: "3003"
      NANGO_LOGS_ENABLED: "false"
    security_opt:
      - no-new-privileges:true
    networks:
      - pgpclaw-internal
    depends_on:
      nango-db:
        condition: service_healthy
      nango-redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3003/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"

  # ════════════════════════════════════════════════════════════
  # BUILD PROFILE (not a running service)
  # ════════════════════════════════════════════════════════════

  # ── Gateway Image Build ─────────────────────────────────────
  gateway-build:
    build:
      context: ./openclaw-gateway
      dockerfile: Dockerfile
    image: pgpclaw/openclaw-gateway:local
    profiles: ["build"]

  # ── Ephemeral Runner Image Build ───────────────────────────
  runner-build:
    build:
      context: ./ephemeral-runner
      dockerfile: Dockerfile
    image: pgpclaw/ephemeral-runner:local
    profiles: ["build"]

volumes:
  prometheus_data:
  grafana_data:
  loki_data:
  oncall_data:
  n8n_data:
  openbao_data:
  openbao_audit:
  nango_db_data:
  nango_redis_data:
