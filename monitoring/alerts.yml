groups:
  # ============================================================================
  # Service Health (Blackbox Probes)
  # ============================================================================
  - name: pgpclaw.health
    rules:

      - alert: ServiceDown
        expr: probe_success == 0
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "{{ $labels.service }} is DOWN"
          description: >-
            Health probe for {{ $labels.service }} has been failing for 2+ minutes.
            Target: {{ $labels.instance }}

      - alert: ServiceSlowResponse
        expr: probe_duration_seconds > 5
        for: 3m
        labels:
          severity: warning
        annotations:
          summary: "{{ $labels.service }} responding slowly"
          description: >-
            {{ $labels.service }} health probe taking {{ $value | humanize }}s
            (threshold: 5s). Target: {{ $labels.instance }}

      - alert: SSLCertExpiringSoon
        expr: probe_ssl_earliest_cert_expiry - time() < 86400 * 30
        for: 1h
        labels:
          severity: warning
        annotations:
          summary: "SSL cert expiring within 30 days"
          description: "Certificate for {{ $labels.instance }} expires in {{ $value | humanize }} seconds"

  # ============================================================================
  # Scrape Target Health
  # ============================================================================
  - name: pgpclaw.scrape
    rules:

      - alert: ScrapeTargetDown
        expr: up == 0
        for: 3m
        labels:
          severity: warning
        annotations:
          summary: "Scrape target {{ $labels.job }} is down"
          description: >-
            Prometheus cannot scrape {{ $labels.instance }} (job: {{ $labels.job }}).
            Last error may indicate network or configuration issue.

      - alert: HighScrapeLatency
        expr: scrape_duration_seconds > 10
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Slow scrape for {{ $labels.job }}"
          description: "Scrape duration: {{ $value | humanize }}s for {{ $labels.instance }}"

  # ============================================================================
  # OpenClaw Security Alerts
  # ============================================================================
  - name: pgpclaw.security
    rules:

      - alert: HighAPIUsage
        expr: sum(rate(openclaw_api_tokens_total[1h])) > 1000000
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "OpenClaw API usage spike"
          description: "Token usage exceeded 1M/hr — possible abuse or runaway agent"

      - alert: SandboxFailures
        expr: sum(increase(openclaw_sandbox_containers_total{status="failed"}[1h])) > 5
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "Sandbox container failures"
          description: "{{ $value }} sandbox failures in last hour"

      - alert: AuthFailures
        expr: sum(increase(openclaw_auth_failures_total[5m])) > 5
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Multiple auth failures detected"
          description: "Possible brute-force attack — {{ $value }} failures in 5 min"

  # ============================================================================
  # Cost Alerts
  # ============================================================================
  - name: pgpclaw.cost
    rules:

      - alert: HourlyCostHigh
        expr: sum(rate(openclaw_api_tokens_total{type="output"}[1h])) * 0.000075 > 20
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "API cost exceeding $20/hour"
          description: "Current hourly burn rate: ${{ $value | humanize }}"

      - alert: MonthlyCostProjectionHigh
        expr: (sum(rate(openclaw_api_tokens_total{type="output"}[24h])) * 0.000075) * 30 > 2000
        for: 15m
        labels:
          severity: warning
        annotations:
          summary: "Projected monthly API cost > $2000"
          description: "At current rate, monthly cost: ${{ $value | humanize }}"

  # ============================================================================
  # OpenBao Alerts
  # ============================================================================
  - name: pgpclaw.openbao
    rules:

      - alert: OpenBaoDown
        expr: probe_success{service="openbao"} == 0
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "OpenBao is unreachable"
          description: >-
            OpenBao health probe has been failing for 2+ minutes.
            The container may be stopped or sealed.
            Check: docker logs pgpclaw-openbao

  # ============================================================================
  # Prometheus Self-Monitoring
  # ============================================================================
  - name: pgpclaw.prometheus
    rules:

      - alert: PrometheusStorageFull
        expr: (prometheus_tsdb_storage_blocks_bytes + prometheus_tsdb_wal_storage_size_bytes) / (5 * 1024 * 1024 * 1024) > 0.9
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Prometheus storage >90% of 5GB limit"
          description: "Current usage: {{ $value | humanize }}% of retention limit"

      - alert: PrometheusConfigReloadFailed
        expr: prometheus_config_last_reload_successful == 0
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Prometheus config reload failed"
          description: "Check prometheus.yml for syntax errors"

      - alert: PrometheusHighMemory
        expr: process_resident_memory_bytes{job="prometheus"} > 1 * 1024 * 1024 * 1024
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "Prometheus using >1GB RAM"
          description: "Current memory: {{ $value | humanize1024 }}B"

  # ============================================================================
  # Grafana Alerts
  # ============================================================================
  - name: pgpclaw.grafana
    rules:

      - alert: GrafanaDown
        expr: up{job="grafana"} == 0
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "Grafana is unreachable"
          description: "Grafana metrics endpoint is not responding"

  # ============================================================================
  # Nango (OAuth) Alerts
  # ============================================================================
  - name: pgpclaw.nango
    rules:

      - alert: NangoDown
        expr: probe_success{service="nango"} == 0
        for: 3m
        labels:
          severity: warning
        annotations:
          summary: "Nango OAuth proxy is unreachable"
          description: >-
            Nango server has been down for 3+ minutes. OAuth-protected
            integrations (Gmail, GitHub, etc.) are unavailable.
